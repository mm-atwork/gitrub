#!/usr/bin/python3
# -*- coding: utf-8 -*-

import argparse
import json
import requests
from datetime import datetime, timezone
from prettytable import PrettyTable

parser = argparse.ArgumentParser()
parser.add_argument("-r", "--repo", help="Search for a specific repo name, list all repos if unset")
parser.add_argument("-t", "--github-token", help="Github token for auth")
parser.add_argument("-o", "--organization", help="User organization to elaborate")
parser.add_argument("--delete", help="Backup and delete a repository - Basically clone and zip locally, then delete on GitHub")
parser.add_argument("--contrib", help="List the single repo contributors along the contributions number.", action="store_true", default=False)

args = parser.parse_args()

# To do: upload to S3 once archived

def main():

    headers = {'Authorization': 'token ' + args.github_token}
    api_baseurl = "https://api.github.com/"
    repos = []

    if args.repo:
        api_url = api_baseurl + 'repos/' + args.organization + "/" + args.repo
        repo = (requests.get(api_url, headers=headers)).json()
        
        if "message" in repo:
            if repo["message"] == "Not Found":
                print("Repository not found, please check if it actually exists")
        else:
              repo['stale'] = "False"
              last_update = get_last_update(repo)
              stale_repo_days = (datetime.now(timezone.utc) - last_update.replace(tzinfo=timezone.utc)).days
              if stale_repo_days > 365:
                  repo['stale'] = "True"

              if not repo['description']:
                  repo['description'] = ""
              else:
                  repo['description'] = (repo['description'][:50] + '..') if len(repo['description']) > 50 else repo['description']

              # Show contributors to repo
              # if args.contrib:
                  # api_url = api_baseurl + 'repos/' + repo["full_name"] + '/contributors'
                  # contrib = (requests.get(api_url, headers=headers)).json()

                  # for contributor in contrib:
                      # print(contributor['login'], contributor['contributions'])
                      
              if args.contrib:
                  try:
                      api_url = api_baseurl + 'repos/' + repo["full_name"] + '/contributors'
                      contrib = (requests.get(api_url, headers=headers)).json()
                      main_contributor = contrib[0]['login']
                  except:
                      main_contributor = "notfound"
              else:
                  main_contributor = ""
              
              repos.append(repo['name'] + '$' + repo['description'] + '$' + last_update.strftime('%Y-%m-%d %H:%M') + "$" + main_contributor + "$" + repo['stale'])
    else:
            
        params = {'per_page':100}
        another_page = True

        api_url = api_baseurl + 'orgs/' + args.organization + '/repos'
        orgs_repos = []
        while another_page:
            r = requests.get(api_url, params=params, headers=headers)
            json_response = json.loads(r.text)
            orgs_repos.append(json_response)

            if 'next' in r.links:
                api_url = r.links['next']['url']
            else:
                another_page=False


        for page in orgs_repos:
           for repo in page:

              last_update = get_last_update(repo)
              stale_repo_days = (datetime.now(timezone.utc) - last_update.replace(tzinfo=timezone.utc)).days

              repo['stale'] = "False"

              if stale_repo_days > 365:
                  repo['stale'] = "True"

              if not repo['description']:
                  repo['description'] = ""
              else:
                  repo['description'] = (repo['description'][:50] + '..') if len(repo['description']) > 50 else repo['description']

              if args.contrib:
                  try:
                      api_url = api_baseurl + 'repos/' + repo["full_name"] + '/contributors'
                      contrib = (requests.get(api_url, headers=headers)).json()
                      # print(contrib[0]['login'])
                      main_contributor = contrib[0]['login']
                  except:
                      main_contributor = "notfound"
              else:
                  main_contributor = ""


              repos.append(repo['name'] + '$' + repo['description'] + '$' + last_update.strftime('%Y-%m-%d %H:%M') + "$" + main_contributor + "$" + repo['stale'])

    arrHeaders = ["Repo", "Description", "LastPush", "MainContributor", "Stale"]

    pt = PrettyTable(arrHeaders)
    pt.align = "l"

    for repo_det in repos:
        pt.add_row(repo_det.split("$"))

    print(pt.get_string(sortby="LastPush"))

def get_last_update(repo):
    last_push = datetime.strptime(repo['pushed_at'], '%Y-%m-%dT%H:%M:%SZ')
    last_commit = datetime.strptime(repo['updated_at'], '%Y-%m-%dT%H:%M:%SZ')

    if last_push > last_commit:
        return last_push
    else:
        return last_commit

if __name__ == '__main__': main()
