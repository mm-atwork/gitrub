#!/usr/bin/python3
# -*- coding: utf-8 -*-

import argparse
import json
import requests
from datetime import datetime, timezone

parser = argparse.ArgumentParser()
parser.add_argument("-r", "--repo", help="Search for a specific repo name, list all repos if unset")
parser.add_argument("-t", "--github-token", help="Github token for auth")
parser.add_argument("-o", "--organization", help="User organization to elaborate")
parser.add_argument("--delete", help="Backup and delete a repository - Basically clone and zip locally, then delete on GitHub")
# parser.add_argument("-q", "--quiet", help="Don't print out the directory structure.", action="store_true", default=False)

args = parser.parse_args()

# To do: upload to S3 once archived

def main():

    headers = {'Authorization': 'token ' + args.github_token}
    api_baseurl = "https://api.github.com/"
    repos = []

    if args.repo:
        api_url = api_baseurl + 'repos/' + args.organization + "/" + args.repo
        print(api_url)
        repo = (requests.get(api_url, headers=headers)).json()
        
        if "message" in repo:
            if repo["message"] == "Not Found":
                print("Repository not found, please check if it actually exists")
        else:
              t = datetime.strptime(repo['updated_at'], '%Y-%m-%dT%H:%M:%SZ')
              stale_repo_days = (datetime.now(timezone.utc) - t.replace(tzinfo=timezone.utc)).days
              if stale_repo_days > 180:
                  if repo['description']:
                      repos.append(repo['full_name'] + ", " + repo['description'] + ", " + t.strftime('%Y-%m-%d %H:%M') + " --- STALE")
                  else:
                      repos.append(repo['full_name'] + ", " + t.strftime('%Y-%m-%d %H:%M') + " --- STALE")
              else:
                  if repo['description']:
                      repos.append(repo['full_name'] + ", " + repo['description'] + ", " + t.strftime('%Y-%m-%d %H:%M'))
                  else:
                      repos.append(repo['full_name'] + ", " + t.strftime('%Y-%m-%d %H:%M'))
        # 'https://api.github.com/repos/' + repo["full_name"]
        # repo = (requests.get(repo["url"], headers=headers)).json()
        # repos.append(repo['name'] + ", " + repo['updated_at'])
    else:

        # orgs_repos = (requests.get(api_baseurl + '/orgs/' + args.organization + '/repos?per_page=100', headers=headers)).json()
        # repos = json.loads(orgs_repos)
        
        # for repo in orgs_repos:
        #    print(repo['full_name'])
            
        params = {'per_page':100}
        another_page = True

        api_url = api_baseurl + 'orgs/' + args.organization + '/repos'
        orgs_repos = []
        while another_page:
            r = requests.get(api_url, params=params, headers=headers)
            json_response = json.loads(r.text)
            orgs_repos.append(json_response)

            if 'next' in r.links:
                api_url = r.links['next']['url']
            else:
                another_page=False


        for page in orgs_repos:
           for repo in page:
              
              t = datetime.strptime(repo['updated_at'], '%Y-%m-%dT%H:%M:%SZ')
              stale_repo_days = (datetime.now(timezone.utc) - t.replace(tzinfo=timezone.utc)).days

              if stale_repo_days > 1300:
                  if repo['description']:
                      repos.append(repo['full_name'] + ", " + repo['description'] + ", " + t.strftime('%Y-%m-%d %H:%M'))
                  else:
                      repos.append(repo['full_name'] + ", " + t.strftime('%Y-%m-%d %H:%M'))


                  # Show contributors to repo
                  # api_url = api_baseurl + 'repos/' + repo["full_name"] + '/contributors'
                  # contrib = (requests.get(api_url, headers=headers)).json()

                  # for contributor in contrib:
                      # print(contributor['login'], contributor['contributions'])
                  
                  # exit()
              
          


    for repo_det in repos:
        print(repo_det)


    # https://api.github.com/repos/OWNER/REPO/zipball/REF

    # url = "https://api.github.com/XXXX?simple=yes&per_page=100&page=1"
    # res=requests.get(url,headers={"Authorization": git_token})
    # repos=res.json()
    # while 'next' in res.links.keys():
      # res=requests.get(res.links['next']['url'],headers={"Authorization": git_token})
      # repos.extend(res.json())


if __name__ == '__main__': main()
